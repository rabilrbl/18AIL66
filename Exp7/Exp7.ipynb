{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the shortened version, the following changes were made:\n",
    "\n",
    "1. Function and variable names were changed to use lowercase with underscores, following Python's naming conventions.\n",
    "2. Unnecessary print statements were removed.\n",
    "3. Code formatting was improved to make it more consistent and readable.\n",
    "4. The code was organized into logical sections for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of Training Data: (13,)\n",
      "The total number of Test Data: (5,)\n",
      "\n",
      "The words or Tokens in the text documents:\n",
      "['am' 'amazing' 'an' 'and' 'awesome' 'bad' 'best' 'boss' 'can' 'deal' 'do'\n",
      " 'enemy' 'fun' 'good' 'great' 'have' 'holiday' 'horrible' 'house' 'is'\n",
      " 'like' 'locality' 'love' 'my' 'not' 'of' 'place' 'restaurant' 'sandwich'\n",
      " 'sick' 'stay' 'stuff' 'that' 'this' 'tired' 'to' 'today' 'tomorrow'\n",
      " 'view' 'we' 'went' 'what' 'will' 'with' 'work']\n",
      "\n",
      "Accuracy of the classifier: 0.8\n",
      "\n",
      "Confusion matrix: [[2 0]\n",
      " [1 2]]\n",
      "\n",
      "The value of Precision: 1.0\n",
      "\n",
      "The value of Recall: 0.6666666666666666\n",
      "I like this place -> 1\n",
      "My boss is my savior -> 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "msg = pd.read_csv('naivetext.csv', names=['message', 'label'])\n",
    "X = msg.message\n",
    "msg['labelnum'] = msg.label.map({'pos': 1, 'neg': 0})\n",
    "y = msg.labelnum\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "print('The total number of Training Data:', y_train.shape)\n",
    "print('The total number of Test Data:', y_test.shape)\n",
    "\n",
    "# Convert text to numerical features\n",
    "count_vect = CountVectorizer()\n",
    "x_train_dtm = count_vect.fit_transform(x_train)\n",
    "x_test_dtm = count_vect.transform(x_test)\n",
    "print('\\nThe words or Tokens in the text documents:')\n",
    "print(count_vect.get_feature_names_out())\n",
    "\n",
    "# Train the classifier and make predictions\n",
    "clf = MultinomialNB().fit(x_train_dtm, y_train)\n",
    "predicted = clf.predict(x_test_dtm)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print('\\nAccuracy of the classifier:', metrics.accuracy_score(y_test, predicted))\n",
    "print('\\nConfusion matrix:', metrics.confusion_matrix(y_test, predicted))\n",
    "print('\\nThe value of Precision:', metrics.precision_score(y_test, predicted))\n",
    "print('\\nThe value of Recall:', metrics.recall_score(y_test, predicted))\n",
    "\n",
    "# Make predictions on new data\n",
    "docs_new = ['I like this place', 'My boss is not my savior']\n",
    "x_new_counts = count_vect.transform(docs_new)\n",
    "predicted_new = clf.predict(x_new_counts)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted_new):\n",
    "    print('%s -> %s' % (doc, msg.labelnum[category]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
